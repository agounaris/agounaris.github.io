<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Stock symbol time series analysis and prediction with ARIMA model | Argy&#39;s Corner</title>
<meta name="keywords" content="" />
<meta name="description" content="This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks.">
<meta name="author" content="Argyrios Gounaris">
<link rel="canonical" href="/2017/05/01/2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.65aebb33e4f0ce3d1a39e4a35c11b91eb08b582489fca0f78f9227d90ac72a52.css" integrity="sha256-Za67M&#43;Twzj0aOeSjXBG5HrCLWCSJ/KD3j5In2QrHKlI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.82.1" />
<link rel="alternate" hreflang="en" href="/2017/05/01/2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model/" />
<meta property="og:title" content="Stock symbol time series analysis and prediction with ARIMA model" />
<meta property="og:description" content="This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2017/05/01/2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model/" /><meta property="og:image" content="/papermod-cover.png"/><meta property="article:section" content="post" />
<meta property="article:published_time" content="2017-05-01T12:00:50&#43;00:00" />
<meta property="article:modified_time" content="2017-05-01T12:00:50&#43;00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/papermod-cover.png"/>

<meta name="twitter:title" content="Stock symbol time series analysis and prediction with ARIMA model"/>
<meta name="twitter:description" content="This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/post/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Stock symbol time series analysis and prediction with ARIMA model",
      "item": "/2017/05/01/2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Stock symbol time series analysis and prediction with ARIMA model",
  "name": "Stock symbol time series analysis and prediction with ARIMA model",
  "description": "This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks.",
  "keywords": [
    
  ],
  "articleBody": "This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks. The Python code in this project can be used to create a reusable module for predicting any combination of symbols with given date ranges.\nPrerequisites NEEDED BACKGROUND The reader must be able to understand econometrics processes and be able to read Python source code. The Python ecosystem offers a great set of tools for scientific computing the libraries can be installed with the pip package management tool. The basic library I will use for this experiment is the statsmodels, a very powerful statistics library offering many statistics functions http://statsmodels.sourceforge.net/devel/index.html#table-of-contents . THE ARIMA MODEL In econometrics and time series analysis the ARIMA model, an acronym for AutoRegressive Integrated Moving Average, is a model that allows us to better understand the time series data and also predict points in the future. The model is represented as ARIMA(p, d, q) when p, d, q are non negative integers and they represent the number of passes on each individual process of the model.\np: corresponds to the “AR” part of the model. An AR(1) is called a first-order auto-regressive model for Y and it defines simple regression with an independent variable being a lagged value of Y(ex Y+1).\nd: corresponds to the “I” part of the model. An I(1) is called a first-order integrated model and it defines the number of the differentiations of the time series in order to make them stationary. We define stationary series as the series whose mean, variance and autocorrelation are constant over time. Stationary series are easier to predict and stationarity can be approximated by differentiating the data points.\nq: corresponds to the “MA” part of the model. An MA(1) is called a first-order moving average model and it defined the lagged forecast errors of the prediction equation.\nDIAGNOSTICS STATIONARITY We can test a time series for stationarity using the “Augmented Dickey - Fuller” test. This is a test which executes a null hypothesis testing that there is a unit-root with the alternative hypothesis that there is no unit root. A unit root is a random trend in time series and it adds a negative effect on any attempt of prediction. If the p-value of the ad-fuller test is above a critical limit then we cannot reject the null hypothesis and the presence of a unit root. Statsmodels offers a function to perform the ad-fuller test on a time series which will be used in this experiment.\nDURBIN WATSON TEST The Durbin-Watsos test is a test statistic which reports the presence of autocorrelation in the time series. As autocorrelation we define the error of a period, transferred to another period. For example the underestimation of some profit for period A causes an underestimation of a profit for period B. This test can returns a value between 0 and 4 with 2 being no autocorrelation and the rest of the values defining the presence of positive autocorrelation (0Code Implementation In order to showcase this process as good as possible, I will describe the code statements in a procedural way.\nNeeded modules import The following statements load all the needed libraries for the execution of the statements. Note the rcParams dictionary. This is a way to customize how the matplotlib plots will be rendered.\n%matplotlib inline import os.path import datetime import pandas as pd import numpy as np import matplotlib.pyplot as plt import pandas_datareader.data as web import statsmodels.api as sm import statsmodels.tsa.api as smt from statsmodels.tsa.arima_model import ARIMA, ARIMAResults from statsmodels.graphics.tsaplots import plot_acf, plot_pacf from matplotlib.pylab import rcParams rcParams['figure.figsize'] = 15, 6 plt.style.use('ggplot') Declaring the data space This is the data we will use to train and test the model. Note that the given date range is not going to work for all stock symbols. The user needs to be aware of the date a specific symbol started to trade otherwise the model will throw errors about missing data.\nsymbol = 'MSFT' source = 'yahoo' start_date = '2008-01-04' end_date = '2017-04-06' predict_days = 2 filename = '{}_{}_to_{}.csv'.format(symbol, start_date, end_date) Retrieving the data To retrieve the data I am using the pandas datareader. Remember the “source” variable from the input declaration step? This is the actual service from where the data will be fetched. On the first run the data are fethced from the remote service and they are stored on a given filename using the csv file format. If you re-run this step the data will be loaded from the saved file. To achieve a naming consistency the filename consists of the symbol name and the date range as declared on the input declaration step.\nstart = datetime.datetime.strptime(start_date, \"%Y-%m-%d\") end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\") if os.path.isfile(filename): data = pd.read_csv(filename, parse_dates=True, index_col=0) else: data = web.DataReader(symbol, source, start, end) data.to_csv(filename) data.tail(5)    Open High Low Close Volume Adj Close   Date           2017-03-31 65.650002 66.190002 65.449997 65.860001 21001100 65.860001   2017-04-03 65.809998 65.940002 65.190002 65.550003 20352800 65.550003   2017-04-04 65.389999 65.809998 65.279999 65.730003 12981200 65.730003   2017-04-05 66.300003 66.349998 65.440002 65.559998 21381100 65.559998   2017-04-06 65.599998 66.059998 65.480003 65.730003 18070500 65.730003     Transforming Data The data from the api do not have available values for the dates the market is closed. This will cause errors on the processing of the data. The ffill method will be userd to add those missing data with the value of the previous available date.\nOn this section I will compile the train and test data. This will be two sliced datasets out of the original time series. During this process I am also filtering out the columns I don’t need keeping just the Close price of the stock, which will be the values up the model will be build.\noriginal_data = data.fillna(method='ffill') ran = pd.date_range(start_date, end_date, freq = 'D') original_data = pd.Series(original_data['Close'], index = ran) plt.plot(original_data) plt.show() original_data = original_data.fillna(method='ffill') split = len(original_data) - predict_days train_data, prediction_data = original_data[0:split], original_data[split:] train_data.tail(5) 2017-03-31 65.860001 2017-04-01 65.860001 2017-04-02 65.860001 2017-04-03 65.550003 2017-04-04 65.730003 Freq: D, Name: Close, dtype: float64  Diagnostics Stationarity For the model to be build we need to check the series for stationarity. The code below renders the autocorrelation and partial autocorrelation charts.\n# rendering such a large time series is compute intensive so I'm breaking it up didive_large_series_by = 10 fig, axes = plt.subplots(1, 2, figsize=(15,4)) fig = plot_acf(train_data, lags = abs(train_data.shape[0]/didive_large_series_by), ax=axes[0]) fig = plot_pacf(train_data, lags = abs(train_data.shape[0]/didive_large_series_by), ax=axes[1]) The autocorrelation plot indicates that the time series are not stationary because the values are not reduced at a significant pace. The partial autocorrelation graph above indicates that the value on lag 1 is the only one which is significantly different from 0, so a model AR(1) should be enough.\nsymbol_diff = train_data - train_data.shift() symbol_diff = symbol_diff.dropna() symbol_diff.head(4) 2008-01-05 0.00 2008-01-06 0.00 2008-01-07 0.23 2008-01-08 -1.16 Freq: D, Name: Close, dtype: float64  plt.plot(symbol_diff) plt.title('First Difference Time Series Plot') plt.show() These are the manual steps that can be followed in order to check a signal for stationarity and transform it to be usable for the ARMA models. Since this process is quite manual and there needs to be way to let the program decide whether a time series is stationary or not I am going to use the Ad-fuller test on the next step.\nAd-fuller test The process above showed how you can check for stationarity and manually transform the time series. With the ad-fuller test we have a process to check for stationarity which, computetionally, is more convenient.\nfrom collections import namedtuple ADF = namedtuple('ADF', 'adf pvalue usedlag nobs critical icbest') stationarity_results = ADF(*smt.adfuller(train_data))._asdict() significance_level = 0.01 if (stationarity_results['pvalue']  significance_level): message = 'For p-value={:0.4f}, the time series are probably non-stationary' print(message.format(stationarity_results['pvalue'])) else: message = 'For p-value={:0.4f}, the time series are probably stationary' print(message.format(stationarity_results['pvalue'])) print(stationarity_results['critical']) For p-value=0.9911, the time series are probably non-stationary {'5%': -2.862399816394662, '1%': -3.4322959703836289, '10%': -2.5672276970758641}  Building the model  I will pick an ARIMA(1,1,1) because of non-stationary time series. I’ve noticed that you cannot use any kind of combination on ARIMA(p, d, q). For example the (1,2,1) fails to converge while the (3,2,1) works better and has smaller error rates. An explanation of ARIMA(1,1,1) could be the following. We need a model which will try to explain data points with their mean, variance and autocorrelation not being constant, by fixing them with differenciation and exponential smoothing. Practically the AR(1) fixes the positive autocorrelation while and MA(1) fixes the negative autocorrelation. Autocorrelation appears a lot in this context. There are many available explanations on what autocorrelation is. Practically when you analyze time series you don’t want the attribute of a specifit data point to affect the attributes of another data point in the future. For example the fact that this months sales are low, should not affect the sales of the next month. You don’t want your data points to be influenced by their own older values. p and q also affect the coefficients of the output. The Nth order creates N coefficients.  order = (1, 0, 1) # if the series are stationary, there is no need for an integrated order if stationarity_results['pvalue']  0.01: order = (1, 1, 1) mod = ARIMA(train_data, order = order, freq = 'D') results = mod.fit() print(results.summary()) print('DW test is {}'.format(sm.stats.durbin_watson(results.resid.values)))  ARIMA Model Results ============================================================================== Dep. Variable: D.Close No. Observations: 3378 Model: ARIMA(1, 1, 1) Log Likelihood -2289.348 Method: css-mle S.D. of innovations 0.477 Date: Thu, 04 May 2017 AIC 4586.697 Time: 16:21:40 BIC 4611.197 Sample: 01-05-2008 HQIC 4595.456 - 04-04-2017 ================================================================================= coef std err z P|z| [0.025 0.975] --------------------------------------------------------------------------------- const 0.0093 0.007 1.405 0.160 -0.004 0.022 ar.L1.D.Close 0.8490 0.059 14.483 0.000 0.734 0.964 ma.L1.D.Close -0.8781 0.053 -16.637 0.000 -0.982 -0.775 Roots ============================================================================= Real Imaginary Modulus Frequency ----------------------------------------------------------------------------- AR.1 1.1779 +0.0000j 1.1779 0.0000 MA.1 1.1388 +0.0000j 1.1388 0.0000 ----------------------------------------------------------------------------- DW test is 2.01217370914  The first thing we need to mention on the summary above is that the true parameters(coef) exist in the 95% confidence interval. The durbin watson test is close to 2 which indicates the lack of autocorrelation.\nprediction = results.predict(prediction_data.index[0], prediction_data.index[-1], typ='levels') prediction.tail(predict_days) 2017-04-05 65.730335 2017-04-06 65.732022 Freq: D, dtype: float64  fig, ax = plt.subplots(figsize=(12, 8)) plt.title(\"Actual Close price Vs. Forecasted Values\") ax = original_data.ix[len(original_data)-predict_days*10:].plot(ax=ax) fig = results.plot_predict(prediction_data.index[0], prediction_data.index[-1], dynamic=True, ax=ax, plot_insample=False) legend = ax.legend(loc='upper left') The graph above shows the predicted values as well and a confidence interval indicating that we can be 95% sure that the price will be between 64.5 and 67. This graph and this confidence interval is rendered for the MSFT symbol using the date range from 2008-01-04 to 2017-04-04 as train data and predicting the dates 2017-04-05 and 2017-04-06.\nOn time series the perfomance of the model is quantified by the mean forecast error which I am calculating on the next step.\nmean_forecast_error = original_data.ix[-predict_days:].sub(prediction).mean() print('Mean forecast error is {:.2%}'.format(abs(mean_forecast_error))) Mean forecast error is 8.62%  Benchmarking I’m going to check the performance of my model towards a naive prediction. Naive prediction is simply the last day’s value as a forecast for the next day. In python you can simulate this by shifting the prices of the original data by one and compare them with the predicted values as bellow.\nnaive_prediction = original_data.tail(predict_days+1).shift(1).tail(predict_days) percentage_change = abs((prediction/naive_prediction-1) *100) df = pd.concat([naive_prediction, prediction, percentage_change], axis=1) df.columns = ['Original', 'Predicted', '% Prediction Diff'] df    Original Predicted % Prediction Diff     2017-04-05 65.730003 65.730335 0.000505   2017-04-06 65.559998 65.732022 0.262391     Compine information Lets try to check the mean errors for a range of prediction days. To do this I use the model I’ve created above and with every iteration I will be calculating again the train and the test data based on the number of the given prediction days.\nmean_errors = [] for number_of_days in range(1, 20): split = len(original_data) - number_of_days train_data, prediction_data = original_data[0:split], original_data[split:] mod = ARIMA(train_data, order = (1, 1, 1), freq = 'D') results = mod.fit(disp=0) prediction = results.predict(prediction_data.index[0], prediction_data.index[-1], typ='levels') original_data_sample = original_data.ix[-number_of_days:] mean_errors.append(abs(original_data_sample.sub(prediction).mean())) plt.plot(mean_errors) plt.show() As we notice there is a good prediction rate up to the first 6 days with a mean error of around 20%. After that the error explodes and it even exceeds the 100% mark on the 15 days.\nOne more interesting experiment is to run the same model for a number of different stock symbols and check how it performs on different signals. I will focus on similar industry symbols.\nsymbols = ['MSFT', 'NVDA', 'CSCO', 'ORCL', 'SYMC', 'INTC', 'EBAY', 'YHOO'] mean_errors = [] for symbol in symbols: # this can be improved with multiprocessing or async calls data = web.DataReader(symbol, source, start, end) original_data = data.fillna(method='ffill') ran = pd.date_range(start_date, end_date, freq = 'D') original_data = pd.Series(original_data['Close'], index = ran) original_data = original_data.fillna(method='ffill') split = len(original_data) - predict_days train_data, prediction_data = original_data[0:split], original_data[split:] mod = ARIMA(train_data, order = (1, 1, 1), freq = 'D') results = mod.fit(disp=0) prediction = results.predict(prediction_data.index[0], prediction_data.index[-1], typ='levels') original_data_sample = original_data.ix[-number_of_days:] mean_errors.append(abs(original_data_sample.sub(prediction).mean())) N = len(mean_errors) x = range(N) width = 1/1.5 plt.bar(x, mean_errors, width, color=\"blue\") plt.xticks(x, symbols) plt.show() The experiment above indicates that for the most symbols there was a very good prediction mean error of less than 20%. The model failed to predict NVIDIA complitelly and was less performant for CISCO and ORACLE.\nConclusions With this exercise I have tested the predictive capabilities of the ARIMA group of models. I have also investigated the performance of my models towards multiple input days and the performance on multiple input symbols for the same date range.\nARIMA proved to be quite performant in most occasions. The mean forecast error for predicting two days for the microsoft stock price proved to be just 0.26% different than the naive benchmark for the same days.\nThere are some cases where the model did not perform well. Henry and Mizon wrote an interesting paper on unpredictability of the econometric modeling and I quote “Unpredictability arises from intrinsic stochastic variation, unexpected instances of outliers, and unanticipated extrinsic shifts of distributions.”. A simple explanation of this could summarized as follows. An econometric model can fail because of internal unknown processes, unexpected failures which affect the train data and changes on external distributions such as the market, economy or governmental policy.\nAnother interesting project, would be to expand this time series analysis and use multiple models for the same prediction period and pick the one which works the best for the specific underlying target. In modern computing systems this process can be spanned across multiple machines and predict multiple combinations of symbols and date ranges in parallel.\nDetailed instructions on how to run this notebook  Probably the easiest solution for non python experts is the anaconda distribution https://www.continuum.io/downloads. It contains a great set of tool for scientific computing out of the box. The full list of available modules is here https://docs.continuum.io/anaconda/pkg-docs. If you will go with this solution jump to step 7. Check your python distribution with python -V. It needs to be at least 2.7 and have the pip package manager installed. Check the pip version with pip -V If case you do not have pip installed check out the instructions here https://pip.pypa.io/en/stable/installing/ Install virtualenv https://virtualenv.pypa.io/en/stable/installation/. Virtualenv is a tool which allows you to have separate python groups of modules in order to keep the global Python installation clean and avoid module versions conflicts. Create a virtual env with the command mkvirtualenv arimamodel and verify you are using this environment with the command workon arimamodel Update pip with pip install -U pip Install all the needed modules with pip install numpy==1.12.1 statsmodels==0.8.0 matplotlib==2.0.0 jupyter==1.0.0 pandas-datareader==0.3.0.post0 Navigate to the directory where this .ipynb file is and run the command jupyter notebook. You should be redirected to the browser and you should be able to select this specific notebook. Make sure you execute each cell to make all the statements available to the code flow. You can run each cell either by selecting it and click on Cell-Run Cell from the top menu or by selecting it and hit the keys Crtl+Enter.  Works cited Ayodele A. Adebiyi, Aderemi O. Adewumi, Charles K. Ayo, “Stock Price Prediction Using the ARIMA Model”, UKSim-AMSS 16th International Conference on Computer Modelling and Simulation 2014\nDavid F. Hendry, Grayham E. Mizon, “Unpredictability in Economic Analysis, Econometric Modeling and Forecasting” University of Oxford 2013\nMichael Wagner, “Forecasting Daily Demand in Cash Supply Chains”, American Journal of Economics and Business Administration 2 (4): 377-383, 2010 ISSN 1945-5488, 2010\nJavier Contreras, Rosario Espínola, Francisco J. Nogales, Antonio J. Conejo, “ARIMA Models to Predict Next-Day Electricity Prices”, IEEE Transactions on power systems, vol 18, no 3, Aug. 2003\nIMPORTANT NOTE This notebook exists for informational purposes only. This analysis does not contain quality predictions. A production system has to cross-validate the findings and predict a greater amount of assets in order to create valid trading strategies. There are no guarantees for accuracy or completeness and this guide can change at any time.\n",
  "wordCount" : "2851",
  "inLanguage": "en",
  "datePublished": "2017-05-01T12:00:50Z",
  "dateModified": "2017-05-01T12:00:50Z",
  "author":{
    "@type": "Person",
    "name": "Argyrios Gounaris"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/2017/05/01/2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Argy's Corner",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Argy&#39;s Corner (Alt + H)">Argy&#39;s Corner</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="/gr/" title="Ελληνικά"
                            aria-label="Ελληνικά">Ελληνικά</a>
                    </li>
                </ul>
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/">Home</a>&nbsp;»&nbsp;<a href="/post/">Posts</a></div>
    <h1 class="post-title">
      Stock symbol time series analysis and prediction with ARIMA model
    </h1>
    <div class="post-meta">May 1, 2017&nbsp;·&nbsp;14 min&nbsp;·&nbsp;Argyrios Gounaris
</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#prerequisites" aria-label="Prerequisites">Prerequisites</a><ul>
                        
                <li>
                    <a href="#needed-background" aria-label="NEEDED BACKGROUND">NEEDED BACKGROUND</a></li>
                <li>
                    <a href="#diagnostics" aria-label="DIAGNOSTICS">DIAGNOSTICS</a><ul>
                        
                <li>
                    <a href="#stationarity" aria-label="STATIONARITY">STATIONARITY</a></li>
                <li>
                    <a href="#durbin-watson-test" aria-label="DURBIN WATSON TEST">DURBIN WATSON TEST</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#code-implementation" aria-label="Code Implementation">Code Implementation</a><ul>
                        
                <li>
                    <a href="#needed-modules-import" aria-label="Needed modules import">Needed modules import</a></li>
                <li>
                    <a href="#declaring-the-data-space" aria-label="Declaring the data space">Declaring the data space</a></li>
                <li>
                    <a href="#retrieving-the-data" aria-label="Retrieving the data">Retrieving the data</a></li>
                <li>
                    <a href="#transforming-data" aria-label="Transforming Data">Transforming Data</a></li></ul>
                </li>
                <li>
                    <a href="#diagnostics-1" aria-label="Diagnostics">Diagnostics</a><ul>
                        
                <li>
                    <a href="#stationarity-1" aria-label="Stationarity">Stationarity</a></li>
                <li>
                    <a href="#ad-fuller-test" aria-label="Ad-fuller test">Ad-fuller test</a></li></ul>
                </li>
                <li>
                    <a href="#building-the-model" aria-label="Building the model">Building the model</a><ul>
                        
                <li>
                    <a href="#benchmarking" aria-label="Benchmarking">Benchmarking</a></li></ul>
                </li>
                <li>
                    <a href="#compine-information" aria-label="Compine information">Compine information</a></li>
                <li>
                    <a href="#conclusions" aria-label="Conclusions">Conclusions</a></li>
                <li>
                    <a href="#detailed-instructions-on-how-to-run-this-notebook" aria-label="Detailed instructions on how to run this notebook">Detailed instructions on how to run this notebook</a></li>
                <li>
                    <a href="#works-cited" aria-label="Works cited">Works cited</a></li>
                <li>
                    <a href="#important-note" aria-label="IMPORTANT NOTE">IMPORTANT NOTE</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>This project examines the predictive capabilities of the ARIMA model for time series analysis. To explore the capabilities of the statsmodels library, the Python programming language will be used with jupyter notebook being the runtime environment. Along with the prediction analysis, there will be a demonstration of data retrieval using the yahoo web api, time series transformation, manual and automatic stationarity checks, benchmarking the model versus a naive benchmark, multiple days prediction and multiple symbol prediction mean error checks. The Python code in this project can be used to create a reusable module for predicting any combination of symbols with given date ranges.</p>
<h1 id="prerequisites">Prerequisites<a hidden class="anchor" aria-hidden="true" href="#prerequisites">#</a></h1>
<h2 id="needed-background">NEEDED BACKGROUND<a hidden class="anchor" aria-hidden="true" href="#needed-background">#</a></h2>
<p>The reader must be able to understand econometrics processes and be able to read Python source code. The Python ecosystem offers a great set of tools for scientific computing the libraries can be installed with the pip package management tool. The basic library I will use for this experiment is the statsmodels, a very powerful statistics library offering many statistics functions <a href="http://statsmodels.sourceforge.net/devel/index.html#table-of-contents">http://statsmodels.sourceforge.net/devel/index.html#table-of-contents</a> .
THE ARIMA MODEL
In econometrics and time series analysis the ARIMA model, an acronym for AutoRegressive Integrated Moving Average, is a model that allows us to better understand the time series data and also predict points in the future. The model is represented as ARIMA(p, d, q) when p, d, q are non negative integers and they represent the number of passes on each individual process of the model.</p>
<p>p: corresponds to the “AR” part of the model. An AR(1) is called a first-order auto-regressive model for Y and it defines simple regression with an independent variable being a lagged value of Y(ex Y+1).</p>
<p>d:  corresponds to the “I” part of the model. An I(1) is called a first-order integrated model and it defines the number of the differentiations of the time series in order to make them stationary. We define stationary series as the series whose mean, variance and autocorrelation are constant over time. Stationary series are easier to predict and stationarity can be approximated by differentiating the data points.</p>
<p>q: corresponds to the “MA” part of the model. An MA(1) is called a first-order moving average model and it defined the lagged forecast errors of the prediction equation.</p>
<h2 id="diagnostics">DIAGNOSTICS<a hidden class="anchor" aria-hidden="true" href="#diagnostics">#</a></h2>
<h3 id="stationarity">STATIONARITY<a hidden class="anchor" aria-hidden="true" href="#stationarity">#</a></h3>
<p>We can test a time series for stationarity using the “Augmented Dickey - Fuller” test. This is a test which executes a null hypothesis testing that there is a unit-root with the alternative hypothesis that there is no unit root. A unit root is a random trend in time series and it adds a negative effect on any attempt of prediction. If the p-value of the ad-fuller test is above a critical limit then we cannot reject the null hypothesis and the presence of a unit root.
Statsmodels offers a function to perform the ad-fuller test on a time series which will be used in this experiment.</p>
<h3 id="durbin-watson-test">DURBIN WATSON TEST<a hidden class="anchor" aria-hidden="true" href="#durbin-watson-test">#</a></h3>
<p>The Durbin-Watsos test is a test statistic which reports the presence of autocorrelation in the time series. As autocorrelation we define the error of a period, transferred to another period. For example the underestimation of some profit for period A causes an underestimation of a profit for period B.
This test can returns a value between 0 and 4 with 2 being no autocorrelation and the rest of the values defining the presence of positive autocorrelation (0&lt;2) and negative autocorrelation (2&lt;4).</p>
<h1 id="code-implementation">Code Implementation<a hidden class="anchor" aria-hidden="true" href="#code-implementation">#</a></h1>
<p>In order to showcase this process as good as possible, I will describe the code statements in a procedural way.</p>
<h2 id="needed-modules-import">Needed modules import<a hidden class="anchor" aria-hidden="true" href="#needed-modules-import">#</a></h2>
<p>The following statements load all the needed libraries for the execution of the statements. Note the rcParams dictionary. This is a way to customize how the matplotlib plots will be rendered.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> os.path
<span style="color:#f92672">import</span> datetime

<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> pandas_datareader.data <span style="color:#f92672">as</span> web
<span style="color:#f92672">import</span> statsmodels.api <span style="color:#f92672">as</span> sm
<span style="color:#f92672">import</span> statsmodels.tsa.api <span style="color:#f92672">as</span> smt

<span style="color:#f92672">from</span> statsmodels.tsa.arima_model <span style="color:#f92672">import</span> ARIMA, ARIMAResults
<span style="color:#f92672">from</span> statsmodels.graphics.tsaplots <span style="color:#f92672">import</span> plot_acf, plot_pacf

<span style="color:#f92672">from</span> matplotlib.pylab <span style="color:#f92672">import</span> rcParams
rcParams[<span style="color:#e6db74">&#39;figure.figsize&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">6</span>
plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(<span style="color:#e6db74">&#39;ggplot&#39;</span>)
</code></pre></div><h2 id="declaring-the-data-space">Declaring the data space<a hidden class="anchor" aria-hidden="true" href="#declaring-the-data-space">#</a></h2>
<p>This is the data we will use to train and test the model. Note that the given date range is not going to work for all stock symbols. The user needs to be aware of the date a specific symbol started to trade otherwise the model will throw errors about missing data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">symbol <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;MSFT&#39;</span>
source <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;yahoo&#39;</span>
start_date <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;2008-01-04&#39;</span>
end_date <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;2017-04-06&#39;</span>
predict_days <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
filename <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;{}_{}_to_{}.csv&#39;</span><span style="color:#f92672">.</span>format(symbol, start_date, end_date)
</code></pre></div><h2 id="retrieving-the-data">Retrieving the data<a hidden class="anchor" aria-hidden="true" href="#retrieving-the-data">#</a></h2>
<p>To retrieve the data I am using the pandas datareader. Remember the &ldquo;source&rdquo; variable from the input declaration step? This is the actual service from where the data will be fetched. On the first run the data are fethced from the remote service and they are stored on a given filename using the csv file format. If you re-run this step the data will be loaded from the saved file. To achieve a naming consistency the filename consists of the symbol name and the date range as declared on the input declaration step.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">start <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>datetime<span style="color:#f92672">.</span>strptime(start_date, <span style="color:#e6db74">&#34;%Y-%m-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#34;</span>)
end <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>datetime<span style="color:#f92672">.</span>strptime(end_date, <span style="color:#e6db74">&#34;%Y-%m-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#34;</span>)

<span style="color:#66d9ef">if</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>isfile(filename):
    data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(filename, parse_dates<span style="color:#f92672">=</span>True, index_col<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
<span style="color:#66d9ef">else</span>:
    data <span style="color:#f92672">=</span> web<span style="color:#f92672">.</span>DataReader(symbol, source, start, end)
    data<span style="color:#f92672">.</span>to_csv(filename)

data<span style="color:#f92672">.</span>tail(<span style="color:#ae81ff">5</span>)
</code></pre></div><div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Volume</th>
      <th>Adj Close</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-03-31</th>
      <td>65.650002</td>
      <td>66.190002</td>
      <td>65.449997</td>
      <td>65.860001</td>
      <td>21001100</td>
      <td>65.860001</td>
    </tr>
    <tr>
      <th>2017-04-03</th>
      <td>65.809998</td>
      <td>65.940002</td>
      <td>65.190002</td>
      <td>65.550003</td>
      <td>20352800</td>
      <td>65.550003</td>
    </tr>
    <tr>
      <th>2017-04-04</th>
      <td>65.389999</td>
      <td>65.809998</td>
      <td>65.279999</td>
      <td>65.730003</td>
      <td>12981200</td>
      <td>65.730003</td>
    </tr>
    <tr>
      <th>2017-04-05</th>
      <td>66.300003</td>
      <td>66.349998</td>
      <td>65.440002</td>
      <td>65.559998</td>
      <td>21381100</td>
      <td>65.559998</td>
    </tr>
    <tr>
      <th>2017-04-06</th>
      <td>65.599998</td>
      <td>66.059998</td>
      <td>65.480003</td>
      <td>65.730003</td>
      <td>18070500</td>
      <td>65.730003</td>
    </tr>
  </tbody>
</table>
</div>
<h2 id="transforming-data">Transforming Data<a hidden class="anchor" aria-hidden="true" href="#transforming-data">#</a></h2>
<p>The data from the api do not have available values for the dates the market is closed. This will cause errors on the processing of the data. The ffill method will be userd to add those missing data with the value of the previous available date.</p>
<p>On this section I will compile the train and test data. This will be two sliced datasets out of the original time series. During this process I am also filtering out the columns I don&rsquo;t need keeping just the Close price of the stock, which will be the values up the model will be build.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">original_data <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>fillna(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ffill&#39;</span>)

ran <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>date_range(start_date, end_date, freq <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;D&#39;</span>)
original_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series(original_data[<span style="color:#e6db74">&#39;Close&#39;</span>], index <span style="color:#f92672">=</span> ran)

plt<span style="color:#f92672">.</span>plot(original_data)
plt<span style="color:#f92672">.</span>show()

original_data <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>fillna(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ffill&#39;</span>)

split <span style="color:#f92672">=</span> len(original_data) <span style="color:#f92672">-</span> predict_days
train_data, prediction_data <span style="color:#f92672">=</span> original_data[<span style="color:#ae81ff">0</span>:split], original_data[split:]

train_data<span style="color:#f92672">.</span>tail(<span style="color:#ae81ff">5</span>)
</code></pre></div><p><img loading="lazy" src="/output_8_0.png" alt="png"  />
</p>
<pre><code>2017-03-31    65.860001
2017-04-01    65.860001
2017-04-02    65.860001
2017-04-03    65.550003
2017-04-04    65.730003
Freq: D, Name: Close, dtype: float64
</code></pre>
<h1 id="diagnostics-1">Diagnostics<a hidden class="anchor" aria-hidden="true" href="#diagnostics-1">#</a></h1>
<h2 id="stationarity-1">Stationarity<a hidden class="anchor" aria-hidden="true" href="#stationarity-1">#</a></h2>
<p>For the model to be build we need to check the series for stationarity. The code below renders the autocorrelation and partial autocorrelation charts.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># rendering such a large time series is compute intensive so I&#39;m breaking it up</span>
didive_large_series_by <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
fig, axes <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">4</span>))
fig <span style="color:#f92672">=</span> plot_acf(train_data,
               lags <span style="color:#f92672">=</span> abs(train_data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">/</span>didive_large_series_by),
               ax<span style="color:#f92672">=</span>axes[<span style="color:#ae81ff">0</span>])
fig <span style="color:#f92672">=</span> plot_pacf(train_data,
                lags <span style="color:#f92672">=</span> abs(train_data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">/</span>didive_large_series_by),
                ax<span style="color:#f92672">=</span>axes[<span style="color:#ae81ff">1</span>])
</code></pre></div><p><img loading="lazy" src="/output_10_0.png" alt="png"  />
</p>
<p>The autocorrelation plot indicates that the time series are not stationary because the values are not reduced at a significant pace. The partial autocorrelation graph above indicates that the value on lag 1 is the only one which is significantly different from 0, so a model AR(1) should be enough.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">symbol_diff <span style="color:#f92672">=</span> train_data <span style="color:#f92672">-</span> train_data<span style="color:#f92672">.</span>shift()
symbol_diff <span style="color:#f92672">=</span> symbol_diff<span style="color:#f92672">.</span>dropna()
symbol_diff<span style="color:#f92672">.</span>head(<span style="color:#ae81ff">4</span>)
</code></pre></div><pre><code>2008-01-05    0.00
2008-01-06    0.00
2008-01-07    0.23
2008-01-08   -1.16
Freq: D, Name: Close, dtype: float64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>plot(symbol_diff)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;First Difference Time Series Plot&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img loading="lazy" src="/output_13_0.png" alt="png"  />
</p>
<p>These are the manual steps that can be followed in order to check a signal for stationarity and transform it to be usable for the ARMA models. Since this process is quite manual and there needs to be way to let the program decide whether a time series is stationary or not I am going to use the Ad-fuller test on the next step.</p>
<h2 id="ad-fuller-test">Ad-fuller test<a hidden class="anchor" aria-hidden="true" href="#ad-fuller-test">#</a></h2>
<p>The process above showed how you can check for stationarity and manually transform the time series. With the ad-fuller test we have a process to check for stationarity which, computetionally, is more convenient.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> namedtuple

ADF <span style="color:#f92672">=</span> namedtuple(<span style="color:#e6db74">&#39;ADF&#39;</span>, <span style="color:#e6db74">&#39;adf pvalue usedlag nobs critical icbest&#39;</span>)
stationarity_results <span style="color:#f92672">=</span> ADF(<span style="color:#f92672">*</span>smt<span style="color:#f92672">.</span>adfuller(train_data))<span style="color:#f92672">.</span>_asdict()
significance_level <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>

<span style="color:#66d9ef">if</span> (stationarity_results[<span style="color:#e6db74">&#39;pvalue&#39;</span>] <span style="color:#f92672">&gt;</span> significance_level):
    message <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;For p-value={:0.4f}, the time series are probably non-stationary&#39;</span>
    <span style="color:#66d9ef">print</span>(message<span style="color:#f92672">.</span>format(stationarity_results[<span style="color:#e6db74">&#39;pvalue&#39;</span>]))
<span style="color:#66d9ef">else</span>:
    message <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;For p-value={:0.4f}, the time series are probably stationary&#39;</span>
    <span style="color:#66d9ef">print</span>(message<span style="color:#f92672">.</span>format(stationarity_results[<span style="color:#e6db74">&#39;pvalue&#39;</span>]))

<span style="color:#66d9ef">print</span>(stationarity_results[<span style="color:#e6db74">&#39;critical&#39;</span>])
</code></pre></div><pre><code>For p-value=0.9911, the time series are probably non-stationary
{'5%': -2.862399816394662, '1%': -3.4322959703836289, '10%': -2.5672276970758641}
</code></pre>
<h1 id="building-the-model">Building the model<a hidden class="anchor" aria-hidden="true" href="#building-the-model">#</a></h1>
<ul>
<li>I will pick an ARIMA(1,1,1) because of non-stationary time series. I&rsquo;ve noticed that you cannot use any kind of combination on ARIMA(p, d, q). For example the (1,2,1) fails to converge while the (3,2,1) works better and has smaller error rates. An explanation of ARIMA(1,1,1) could be the following. We need a model which will try to explain data points with their mean, variance and autocorrelation not being constant, by fixing them with differenciation and exponential smoothing. Practically the AR(1) fixes the positive autocorrelation while and MA(1) fixes the negative autocorrelation. Autocorrelation appears a lot in this context. There are many available explanations on what autocorrelation is. Practically when you analyze time series you don&rsquo;t want the attribute of a specifit data point to affect the attributes of another data point in the future. For example the fact that this months sales are low, should not affect the sales of the next month. You don&rsquo;t want your data points to be influenced by their own older values.</li>
<li>p and q also affect the coefficients of the output. The Nth order creates N coefficients.</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#75715e"># if the series are stationary, there is no need for an integrated order</span>
<span style="color:#66d9ef">if</span> stationarity_results[<span style="color:#e6db74">&#39;pvalue&#39;</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.01</span>:
    order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)

mod <span style="color:#f92672">=</span> ARIMA(train_data, order <span style="color:#f92672">=</span> order, freq <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;D&#39;</span>)

results <span style="color:#f92672">=</span> mod<span style="color:#f92672">.</span>fit()
<span style="color:#66d9ef">print</span>(results<span style="color:#f92672">.</span>summary())
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;DW test is {}&#39;</span><span style="color:#f92672">.</span>format(sm<span style="color:#f92672">.</span>stats<span style="color:#f92672">.</span>durbin_watson(results<span style="color:#f92672">.</span>resid<span style="color:#f92672">.</span>values)))
</code></pre></div><pre><code>                             ARIMA Model Results
==============================================================================
Dep. Variable:                D.Close   No. Observations:                 3378
Model:                 ARIMA(1, 1, 1)   Log Likelihood               -2289.348
Method:                       css-mle   S.D. of innovations              0.477
Date:                Thu, 04 May 2017   AIC                           4586.697
Time:                        16:21:40   BIC                           4611.197
Sample:                    01-05-2008   HQIC                          4595.456
                         - 04-04-2017
=================================================================================
                    coef    std err          z      P&gt;|z|      [0.025      0.975]
---------------------------------------------------------------------------------
const             0.0093      0.007      1.405      0.160      -0.004       0.022
ar.L1.D.Close     0.8490      0.059     14.483      0.000       0.734       0.964
ma.L1.D.Close    -0.8781      0.053    -16.637      0.000      -0.982      -0.775
                                    Roots
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            1.1779           +0.0000j            1.1779            0.0000
MA.1            1.1388           +0.0000j            1.1388            0.0000
-----------------------------------------------------------------------------
DW test is 2.01217370914
</code></pre>
<p>The first thing we need to mention on the summary above is that the true parameters(coef) exist in the 95% confidence interval. The durbin watson test is close to 2 which indicates the lack of autocorrelation.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">prediction <span style="color:#f92672">=</span> results<span style="color:#f92672">.</span>predict(prediction_data<span style="color:#f92672">.</span>index[<span style="color:#ae81ff">0</span>],
                             prediction_data<span style="color:#f92672">.</span>index[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],
                             typ<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;levels&#39;</span>)
prediction<span style="color:#f92672">.</span>tail(predict_days)
</code></pre></div><pre><code>2017-04-05    65.730335
2017-04-06    65.732022
Freq: D, dtype: float64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Actual Close price Vs. Forecasted Values&#34;</span>)
ax <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>ix[len(original_data)<span style="color:#f92672">-</span>predict_days<span style="color:#f92672">*</span><span style="color:#ae81ff">10</span>:]<span style="color:#f92672">.</span>plot(ax<span style="color:#f92672">=</span>ax)
fig <span style="color:#f92672">=</span> results<span style="color:#f92672">.</span>plot_predict(prediction_data<span style="color:#f92672">.</span>index[<span style="color:#ae81ff">0</span>],
                           prediction_data<span style="color:#f92672">.</span>index[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],
                           dynamic<span style="color:#f92672">=</span>True,
                           ax<span style="color:#f92672">=</span>ax,
                           plot_insample<span style="color:#f92672">=</span>False)
legend <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;upper left&#39;</span>)
</code></pre></div><p><img loading="lazy" src="/output_21_0.png" alt="png"  />
</p>
<p>The graph above shows the predicted values as well and a confidence interval indicating that we can be 95% sure that the price will be between 64.5 and 67. This graph and this confidence interval is rendered for the MSFT symbol using the date range from 2008-01-04 to 2017-04-04 as train data and predicting the dates 2017-04-05 and 2017-04-06.</p>
<p>On time series the perfomance of the model is quantified by the mean forecast error which I am calculating on the next step.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">mean_forecast_error <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>ix[<span style="color:#f92672">-</span>predict_days:]<span style="color:#f92672">.</span>sub(prediction)<span style="color:#f92672">.</span>mean()
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Mean forecast error is {:.2%}&#39;</span><span style="color:#f92672">.</span>format(abs(mean_forecast_error)))
</code></pre></div><pre><code>Mean forecast error is 8.62%
</code></pre>
<h2 id="benchmarking">Benchmarking<a hidden class="anchor" aria-hidden="true" href="#benchmarking">#</a></h2>
<p>I&rsquo;m going to check the performance of my model towards a naive prediction. Naive prediction is simply the last day&rsquo;s value as a forecast for the next day. In python you can simulate this by shifting the prices of the original data by one and compare them with the predicted values as bellow.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">naive_prediction <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>tail(predict_days<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>shift(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>tail(predict_days)
percentage_change <span style="color:#f92672">=</span> abs((prediction<span style="color:#f92672">/</span>naive_prediction<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span><span style="color:#ae81ff">100</span>)
df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([naive_prediction, prediction, percentage_change], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
df<span style="color:#f92672">.</span>columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Original&#39;</span>, <span style="color:#e6db74">&#39;Predicted&#39;</span>, <span style="color:#e6db74">&#39;% Prediction Diff&#39;</span>]
df
</code></pre></div><div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Original</th>
      <th>Predicted</th>
      <th>% Prediction Diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-04-05</th>
      <td>65.730003</td>
      <td>65.730335</td>
      <td>0.000505</td>
    </tr>
    <tr>
      <th>2017-04-06</th>
      <td>65.559998</td>
      <td>65.732022</td>
      <td>0.262391</td>
    </tr>
  </tbody>
</table>
</div>
<h1 id="compine-information">Compine information<a hidden class="anchor" aria-hidden="true" href="#compine-information">#</a></h1>
<p>Lets try to check the mean errors for a range of prediction days. To do this I use the model I&rsquo;ve created above and with every iteration I will be calculating again the train and the test data based on the number of the given prediction days.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">mean_errors <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> number_of_days <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">20</span>):
    split <span style="color:#f92672">=</span> len(original_data) <span style="color:#f92672">-</span> number_of_days
    train_data, prediction_data <span style="color:#f92672">=</span> original_data[<span style="color:#ae81ff">0</span>:split], original_data[split:]
    mod <span style="color:#f92672">=</span> ARIMA(train_data, order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), freq <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;D&#39;</span>)
    results <span style="color:#f92672">=</span> mod<span style="color:#f92672">.</span>fit(disp<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    prediction <span style="color:#f92672">=</span> results<span style="color:#f92672">.</span>predict(prediction_data<span style="color:#f92672">.</span>index[<span style="color:#ae81ff">0</span>],
                                 prediction_data<span style="color:#f92672">.</span>index[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],
                                 typ<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;levels&#39;</span>)
    original_data_sample <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>ix[<span style="color:#f92672">-</span>number_of_days:]
    mean_errors<span style="color:#f92672">.</span>append(abs(original_data_sample<span style="color:#f92672">.</span>sub(prediction)<span style="color:#f92672">.</span>mean()))

plt<span style="color:#f92672">.</span>plot(mean_errors)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img loading="lazy" src="/output_27_0.png" alt="png"  />
</p>
<p>As we notice there is a good prediction rate up to the first 6 days with a mean error of around 20%. After that the error explodes and it even exceeds the 100% mark on the 15 days.</p>
<p>One more interesting experiment is to run the same model for a number of different stock symbols and check how it performs on different signals. I will focus on similar industry symbols.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">symbols <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;MSFT&#39;</span>, <span style="color:#e6db74">&#39;NVDA&#39;</span>, <span style="color:#e6db74">&#39;CSCO&#39;</span>, <span style="color:#e6db74">&#39;ORCL&#39;</span>, <span style="color:#e6db74">&#39;SYMC&#39;</span>, <span style="color:#e6db74">&#39;INTC&#39;</span>, <span style="color:#e6db74">&#39;EBAY&#39;</span>, <span style="color:#e6db74">&#39;YHOO&#39;</span>]
mean_errors <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> symbol <span style="color:#f92672">in</span> symbols: <span style="color:#75715e"># this can be improved with multiprocessing or async calls</span>
    data <span style="color:#f92672">=</span> web<span style="color:#f92672">.</span>DataReader(symbol, source, start, end)
    original_data <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>fillna(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ffill&#39;</span>)

    ran <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>date_range(start_date, end_date, freq <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;D&#39;</span>)
    original_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series(original_data[<span style="color:#e6db74">&#39;Close&#39;</span>], index <span style="color:#f92672">=</span> ran)

    original_data <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>fillna(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ffill&#39;</span>)

    split <span style="color:#f92672">=</span> len(original_data) <span style="color:#f92672">-</span> predict_days
    train_data, prediction_data <span style="color:#f92672">=</span> original_data[<span style="color:#ae81ff">0</span>:split], original_data[split:]
    mod <span style="color:#f92672">=</span> ARIMA(train_data, order <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), freq <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;D&#39;</span>)
    results <span style="color:#f92672">=</span> mod<span style="color:#f92672">.</span>fit(disp<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    prediction <span style="color:#f92672">=</span> results<span style="color:#f92672">.</span>predict(prediction_data<span style="color:#f92672">.</span>index[<span style="color:#ae81ff">0</span>],
                                 prediction_data<span style="color:#f92672">.</span>index[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],
                                 typ<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;levels&#39;</span>)
    original_data_sample <span style="color:#f92672">=</span> original_data<span style="color:#f92672">.</span>ix[<span style="color:#f92672">-</span>number_of_days:]
    mean_errors<span style="color:#f92672">.</span>append(abs(original_data_sample<span style="color:#f92672">.</span>sub(prediction)<span style="color:#f92672">.</span>mean()))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">N <span style="color:#f92672">=</span> len(mean_errors)
x <span style="color:#f92672">=</span> range(N)
width <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">1.5</span>
plt<span style="color:#f92672">.</span>bar(x, mean_errors, width, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;blue&#34;</span>)
plt<span style="color:#f92672">.</span>xticks(x, symbols)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img loading="lazy" src="/output_30_0.png" alt="png"  />
</p>
<p>The experiment above indicates that for the most symbols there was a very good prediction mean error of less than 20%. The model failed to predict NVIDIA complitelly and was less performant for CISCO and ORACLE.</p>
<h1 id="conclusions">Conclusions<a hidden class="anchor" aria-hidden="true" href="#conclusions">#</a></h1>
<p>With this exercise I have tested the predictive capabilities of the ARIMA group of models. I have also investigated the performance of my models towards multiple input days and the performance on multiple input symbols for the same date range.</p>
<p>ARIMA proved to be quite performant in most occasions. The mean forecast error for predicting two days for the microsoft stock price proved to be just 0.26% different than the naive benchmark for the same days.</p>
<p>There are some cases where the model did not perform well. Henry and Mizon wrote an interesting paper on unpredictability of the econometric modeling and I quote “Unpredictability arises from intrinsic stochastic variation, unexpected instances of outliers, and unanticipated extrinsic shifts of distributions.”.  A simple explanation of this could summarized as follows. An econometric model can fail because of internal unknown processes, unexpected failures which affect the train data and changes on external distributions such as the market, economy or governmental policy.</p>
<p>Another interesting project, would be to expand this time series analysis and use multiple models for the same prediction period and pick the one which works the best for the specific underlying target. In modern computing systems this process can be spanned across multiple machines and predict multiple combinations of symbols and date ranges in parallel.</p>
<h1 id="detailed-instructions-on-how-to-run-this-notebook">Detailed instructions on how to run this notebook<a hidden class="anchor" aria-hidden="true" href="#detailed-instructions-on-how-to-run-this-notebook">#</a></h1>
<ol>
<li>Probably the easiest solution for non python experts is the anaconda distribution <a href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</a>. It contains a great set of tool for scientific computing out of the box. The full list of available modules is here <a href="https://docs.continuum.io/anaconda/pkg-docs">https://docs.continuum.io/anaconda/pkg-docs</a>. If you will go with this solution jump to step 7.</li>
<li>Check your python distribution with <code>python -V</code>. It needs to be at least 2.7 and have the pip package manager installed. Check the pip version with <code>pip -V</code>
If case you do not have pip installed check out the instructions here <a href="https://pip.pypa.io/en/stable/installing/">https://pip.pypa.io/en/stable/installing/</a></li>
<li>Install virtualenv <a href="https://virtualenv.pypa.io/en/stable/installation/">https://virtualenv.pypa.io/en/stable/installation/</a>. Virtualenv is a tool which allows you to have separate python groups of modules in order to keep the global Python installation clean and avoid module versions conflicts.</li>
<li>Create a virtual env with the command <code>mkvirtualenv arimamodel</code> and verify you are using this environment with the command <code>workon arimamodel</code></li>
<li>Update pip with <code>pip install -U pip</code></li>
<li>Install all the needed modules with <code>pip install numpy==1.12.1 statsmodels==0.8.0 matplotlib==2.0.0 jupyter==1.0.0 pandas-datareader==0.3.0.post0</code></li>
<li>Navigate to the directory where this .ipynb file is and run the command <code>jupyter notebook</code>. You should be redirected to the browser and you should be able to select this specific notebook.</li>
<li>Make sure you execute each cell to make all the statements available to the code flow. You can run each cell either by selecting it and click on Cell-&gt;Run Cell from the top menu or by selecting it and hit the keys Crtl+Enter.</li>
</ol>
<h1 id="works-cited">Works cited<a hidden class="anchor" aria-hidden="true" href="#works-cited">#</a></h1>
<p>Ayodele A. Adebiyi, Aderemi O. Adewumi, Charles K. Ayo, “Stock Price Prediction Using
the ARIMA Model”, UKSim-AMSS 16th International Conference on Computer Modelling
and Simulation 2014</p>
<p>David F. Hendry, Grayham E. Mizon, “Unpredictability in Economic Analysis, Econometric Modeling and Forecasting” University of Oxford 2013</p>
<p>Michael Wagner, “Forecasting Daily Demand in Cash Supply Chains”, American Journal of
Economics and Business Administration 2 (4): 377-383, 2010 ISSN 1945-5488, 2010</p>
<p>Javier Contreras, Rosario Espínola, Francisco J. Nogales, Antonio J. Conejo, “ARIMA
Models to Predict Next-Day Electricity Prices”, IEEE Transactions on power systems, vol 18,
no 3, Aug. 2003</p>
<h1 id="important-note">IMPORTANT NOTE<a hidden class="anchor" aria-hidden="true" href="#important-note">#</a></h1>
<p>This notebook exists for informational purposes only. This analysis does not contain quality predictions. A production system has to cross-validate the findings and predict a greater amount of assets in order to create valid trading strategies. There are no guarantees for accuracy or completeness and this guide can change at any time.</p>

</div>
  <footer class="post-footer">
<nav class="paginav">
  <a class="next" href="/2015/02/28/2015-02-16-asynchronous-python3-parallel-tasks/">
    <span class="title">Next Page »</span>
    <br>
    <span>Asynchronous tasks with python3 concurrent futures</span>
  </a>
</nav>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on twitter"
        href="https://twitter.com/intent/tweet/?text=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model&amp;url=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f&amp;hashtags=">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f&amp;title=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model&amp;summary=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model&amp;source=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on reddit"
        href="https://reddit.com/submit?url=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f&title=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on whatsapp"
        href="https://api.whatsapp.com/send?text=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model%20-%20%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stock symbol time series analysis and prediction with ARIMA model on telegram"
        href="https://telegram.me/share/url?text=Stock%20symbol%20time%20series%20analysis%20and%20prediction%20with%20ARIMA%20model&amp;url=%2f2017%2f05%2f01%2f2017-05-01-stock-symbol-time-series-analysis-and-prediction-with-arima-model%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="/">Argy&#39;s Corner</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
